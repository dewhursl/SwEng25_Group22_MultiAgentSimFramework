{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Negotiation begins.\n",
      "\n",
      "\n",
      "Turn 1:\n",
      "\n",
      "Customer:\n",
      "Hello, I'm interested in buying this car.\n",
      "\n",
      "Salesperson:\n",
      "I can see why you'd be interested - it's a great model with plenty of features. We've got a really good price on this one, $29,500. Is that within your budget?\n",
      "\n",
      "Turn 2:\n",
      "\n",
      "Customer:\n",
      "That's slightly above my budget. Can we discuss lowering the price some, though you didn't want to start too high?\n",
      "\n",
      "Salesperson:\n",
      "I can definitely see where compromise comes in here. My lowest I could go would be $28,250, but I'd still need to make a few dollars on this sale. Would that work for you?\n",
      "\n",
      "Turn 3:\n",
      "\n",
      "Customer:\n",
      "No, not there yet. Can we meet around $27,800 then? I've been doing some research and found that price is closer to fair market value, let's discuss further.\n",
      "\n",
      "Salesperson:\n",
      "I'm not quite ready to concede just yet. If we take it down to $28,000, I can throw in some aftermarket accessories that add significant value to the vehicle, making it a better deal overall.\n",
      "\n",
      "Turn 4:\n",
      "\n",
      "Customer:\n",
      "That sounds like a good compromise, but only if you can meet me at $27,200. Those are quite expensive aftermarket accessories and I'd need them to be seriously justified by such a low price.\n",
      "\n",
      "Salesperson:\n",
      "I think we're getting close. At $28,000, the accessories would still be worth it, but I'm willing to do one better for you - how about we meet exactly at $27,800? That's the lowest I can go without barely breaking even on the sale.\n",
      "\n",
      "Customer accepted the deal.\n",
      "\n",
      "Conversation saved to negotiation_log.json.\n",
      "Starting HTTP server on port 8000...\n",
      "Serving HTTP on port 8000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [08/Feb/2025 19:49:17] \"GET /index.html HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Feb/2025 19:52:18] \"GET /index.html HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Feb/2025 19:52:18] \"GET /images/sales.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Feb/2025 19:52:18] \"GET /images/customer.jpg HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 130\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    129\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mrun(simulation())\n\u001b[0;32m--> 130\u001b[0m     \u001b[43mstart_http_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 119\u001b[0m, in \u001b[0;36mstart_http_server\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         server \u001b[38;5;241m=\u001b[39m httpd\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mServing HTTP on port \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 119\u001b[0m         \u001b[43mhttpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve_forever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m48\u001b[39m:  \u001b[38;5;66;03m# Address already in use\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-agent-prototypes/lib/python3.13/socketserver.py:235\u001b[0m, in \u001b[0;36mBaseServer.serve_forever\u001b[0;34m(self, poll_interval)\u001b[0m\n\u001b[1;32m    232\u001b[0m selector\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mself\u001b[39m, selectors\u001b[38;5;241m.\u001b[39mEVENT_READ)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__shutdown_request:\n\u001b[0;32m--> 235\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# bpo-35017: shutdown() called during select(), exit immediately.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__shutdown_request:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-agent-prototypes/lib/python3.13/selectors.py:398\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    396\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json, os, asyncio\n",
    "import nest_asyncio\n",
    "from http.server import SimpleHTTPRequestHandler\n",
    "from socketserver import TCPServer\n",
    "nest_asyncio.apply()\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "customer_budget = 25000\n",
    "salesperson_target = 30000\n",
    "\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"llama3.2\",\n",
    "    base_url=\"http://localhost:11434/v1\", \n",
    "    model_info={\n",
    "        \"vision\": False,\n",
    "        \"function_calling\": True,\n",
    "        \"json_output\": False,\n",
    "        \"family\": \"unknown\"\n",
    "    }\n",
    ")\n",
    "\n",
    "customer = AssistantAgent(\n",
    "        name=\"customer\",\n",
    "        model_client=model_client,\n",
    "        system_message=f\"You are a customer buying a car who wants a lower price, don't accept the salesperson's first offer because it will be too high. don't reveal your budget. At the start, Offer a price less than your budget of {customer_budget} but be willing to increase it gradually but not more than your budget\"+\\\n",
    "                        f\"if salesperson offers a price which is cheaper than your budget {customer_budget}, you can accept the deal and say 'I ACCEPT'\"+\\\n",
    "                        f\"if salesperson offers a price higher than your budget {customer_budget}, say it's too high and do not accept it, try to negotiate it lower, only talk about the price, don't keep asking other questions or doing a test drive. give short 1-2 sentence responses, don't describe actions\"\n",
    ")\n",
    "\n",
    "salesperson = AssistantAgent(\n",
    "        name=\"salesperson\",\n",
    "        model_client=model_client,\n",
    "        system_message=f\"You are a salesperson negotiating the price of a particular car with a customer, you don't want to accept a price that is too low. At the start offer higher price of {salesperson_target} but if they don't accept you are willing to lower it gradually. \"+\\\n",
    "                        \"Don't offer a lower price than the customer, offer a slightly higher price than them or accept their offer. give short 1-2 sentence responses, don't describe actions\"\n",
    ")\n",
    "\n",
    "async def simulation():\n",
    "    print(\"\\nNegotiation begins.\\n\")\n",
    "    turn_count = 1\n",
    "    cancellation_token = CancellationToken()\n",
    "\n",
    "    conversation_log = []     # Store conversation history to be converted to JSON output format\n",
    "\n",
    "    customer_text = \"Hello, I'm interested in buying this car.\"\n",
    "    conversation_history = [TextMessage(content=customer_text, source=\"customer\")]\n",
    "    \n",
    "    while turn_count <= 10:  # if stopping condition is not met, end after 10 turns\n",
    "        print(f\"\\nTurn {turn_count}:\")\n",
    "        print(\"\\nCustomer:\\n\" + customer_text)\n",
    "\n",
    "        # Log the customer's message\n",
    "        conversation_log.append({\n",
    "            \"turn\": turn_count,\n",
    "            \"role\": \"customer\",\n",
    "            \"message\": customer_text\n",
    "        })\n",
    "\n",
    "        salesperson_response = await salesperson.on_messages(\n",
    "            conversation_history,\n",
    "            cancellation_token=cancellation_token,\n",
    "        )\n",
    "        salesperson_text = salesperson_response.chat_message.content\n",
    "        print(\"\\nSalesperson:\\n\" + salesperson_text)\n",
    "\n",
    "        conversation_log.append({\n",
    "            \"turn\": turn_count,\n",
    "            \"role\": \"salesperson\",\n",
    "            \"message\": salesperson_text\n",
    "        })\n",
    "\n",
    "        conversation_history.append(TextMessage(content=salesperson_text, source=\"salesperson\"))\n",
    "\n",
    "        customer_response = await customer.on_messages(\n",
    "            conversation_history,\n",
    "            cancellation_token=cancellation_token,\n",
    "        )\n",
    "        customer_text = customer_response.chat_message.content\n",
    "        conversation_history.append(TextMessage(content=customer_text, source=\"customer\"))\n",
    "\n",
    "        if \"i accept\" in customer_text.lower():\n",
    "            print(\"\\nCustomer accepted the deal.\")\n",
    "            conversation_log.append({ # log their last message which is not printed\n",
    "            \"turn\": turn_count,\n",
    "            \"role\": \"customer\",\n",
    "            \"message\": customer_text\n",
    "        })\n",
    "            break\n",
    "        elif \"leave\" in customer_text.lower():\n",
    "            print(\"\\nCustomer decided to leave.\")\n",
    "            conversation_log.append({ # log their last message which is not printed\n",
    "            \"turn\": turn_count,\n",
    "            \"role\": \"customer\",\n",
    "            \"message\": customer_text\n",
    "        })\n",
    "            break\n",
    "\n",
    "        turn_count += 1  \n",
    "\n",
    "    # Convert the conversation log to JSON and save to file\n",
    "    with open(\"negotiation_log.json\", \"w\") as f:\n",
    "        json.dump({\"conversation\": conversation_log}, f, indent=4)\n",
    "\n",
    "    print(\"\\nConversation saved to negotiation_log.json.\")\n",
    "\n",
    "def start_http_server():\n",
    "    os.chdir(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "    port = 8000  # Port number for the HTTP server\n",
    "    server = None\n",
    "\n",
    "    try:\n",
    "        print(f\"Starting HTTP server on port {port}...\")\n",
    "        with TCPServer((\"\", port), SimpleHTTPRequestHandler) as httpd:\n",
    "            server = httpd\n",
    "            print(f\"Serving HTTP on port {port}...\")\n",
    "            httpd.serve_forever()\n",
    "\n",
    "    except OSError as e:\n",
    "        if e.errno == 48:  # Address already in use\n",
    "            print(f\"Port {port} is already in use. Attempting to free up and retry...\")\n",
    "            if server:\n",
    "                server.server_close()\n",
    "            start_http_server() \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(simulation())\n",
    "    start_http_server()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-agent-prototypes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
